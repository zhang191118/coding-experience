### 第一步：从核心开始 - 构建一个线程安全的内存存储

万事开头难，但我们可以从最简单的模型入手。一个 KV 数据库，其核心就是一个能存储键值对的地方。在 Go 里，`map` 是最天然的选择。

但在我们的系统中，比如“机构项目管理系统”的后台服务，会有成百上千的用户同时操作，并发读写是常态。直接使用原生 `map` 会导致竞态问题，数据会被写花。因此，第一步就是要保证线程安全。

最直接的工具就是 `sync.RWMutex`（读写锁）。它允许多个“读”操作同时进行，但“写”操作是排他的。这非常符合我们“读多写少”的缓存场景，比如频繁读取项目配置，偶尔才更新一次。

下面是我们的第一版核心存储结构：

```go
package kvstore

import "sync"

// KVStore 是一个线程安全的内存键值存储
type KVStore struct {
	mu   sync.RWMutex
	data map[string][]byte // 值我们用 []byte 存储，更通用
}

// NewKVStore 创建一个新的 KVStore 实例
func NewKVStore() *KVStore {
	return &KVStore{
		data: make(map[string][]byte),
	}
}

// Set 存储一个键值对
func (s *KVStore) Set(key string, value []byte) error {
	s.mu.Lock() // 获取写锁，独占
	defer s.mu.Unlock()
	s.data[key] = value
	return nil
}

// Get 获取一个键对应的值
func (s *KVStore) Get(key string) ([]byte, bool) {
	s.mu.RLock() // 获取读锁，共享
	defer s.mu.RUnlock()
	value, found := s.data[key]
	return value, found
}

// Delete 删除一个键值对
func (s *KVStore) Delete(key string) error {
	s.mu.Lock() // 获取写锁，独占
	defer s.mu.Unlock()
	delete(s.data, key)
	return nil
}
```

**关键细节**：
*   **为什么用 `[]byte` 而不是 `string`？** 在实际业务中，我们存储的值可能是 JSON 字符串、Protobuf 序列化的二进制数据，甚至是小的图片文件。`[]byte` 是最通用的数据类型，避免了不必要的类型转换。
*   **读写锁的选择**：`RWMutex` 在读多写少的场景下性能优于 `Mutex`。如果你的场景是写操作非常频繁，那么直接用 `Mutex` 可能开销更小，因为 `RWMutex` 的调度本身也有成本。

### 第二步：提供服务 - 使用 Go-Zero 封装成 API

光有存储核心还不够，我们需要让它能被其他服务访问。在我们的微服务架构中，`go-zero` 是标准框架。下面我们就用 `go-zero` 把这个 KV 存储包装成一个独立的微服务。

假设这个服务是我们“智能开放平台”的一部分，专门提供临时的配置存储能力。

**1. 定义 API (`kv.api`)**

```api
type (
	SetRequest {
		Key   string `json:"key"`
		Value string `json:"value"` // 为方便演示，API层面使用string
	}

	SetResponse {}

	GetRequest {
		Key string `path:"key"`
	}

	GetResponse {
		Value string `json:"value"`
	}

	DeleteRequest {
		Key string `path:"key"`
	}

	DeleteResponse {}
)

service kv-api {
	@handler KVHandler
	post /kv (SetRequest) returns (SetResponse)
	get /kv/:key (GetRequest) returns (GetResponse)
	delete /kv/:key (DeleteRequest) returns (DeleteResponse)
}
```

**2. 在 `ServiceContext` 中注入 KVStore 实例**

我们需要让 `KVStore` 成为一个单例，在整个服务生命周期内共享。

```go
// service/servicecontext.go
import "path/to/your/kvstore"

type ServiceContext struct {
	Config config.Config
	Store  *kvstore.KVStore
}

func NewServiceContext(c config.Config) *ServiceContext {
	return &ServiceContext{
		Config: c,
		Store:  kvstore.NewKVStore(), // 在这里初始化
	}
}
```

**3. 实现 `logic`**

现在，我们可以在 `logic` 文件中调用 `KVStore` 的方法了。

```go
// logic/setlogic.go
func (l *SetLogic) Set(req *types.SetRequest) (resp *types.SetResponse, err error) {
	if req.Key == "" {
		return nil, errors.New("key cannot be empty")
	}

	// 将API层的string转为[]byte存入
	err = l.svcCtx.Store.Set(req.Key, []byte(req.Value))
	if err != nil {
		return nil, err
	}

	return &types.SetResponse{}, nil
}

// logic/getlogic.go
func (l *GetLogic) Get(req *types.GetRequest) (resp *types.GetResponse, err error) {
	value, found := l.svcCtx.Store.Get(req.Key)
	if !found {
		// 在API层面，通常我们用HTTP状态码来表示资源未找到
		return nil, status.Error(404, "key not found")
	}

	return &types.GetResponse{
		Value: string(value), // 将[]byte转回string返回
	}, nil
}
```
*（`DeleteLogic` 的实现与此类似，这里不再赘述）*

通过 `goctl` 工具生成代码后，我们就拥有了一个功能完备的、基于 HTTP 的 KV 服务。这在开发联调阶段非常有用，可以快速模拟依赖服务的数据。

### 第三步：保证数据不丢 - 实现简单的持久化（WAL）

内存存储速度飞快，但致命弱点是服务一重启，数据就全没了。在我们的 ePRO 系统中，患者提交的数据是绝对不能丢失的。即便只是临时缓存，也需要有恢复机制。

最经典的持久化方案之一是**预写日志（Write-Ahead Logging, WAL）**。

**核心思想**：在对数据进行任何修改（Set 或 Delete）之前，先把这个“操作”记录到一个日志文件里。即使此时服务崩溃，重启后我们也可以通过回放这个日志文件，将内存状态恢复到崩溃前的样子。

下面我们来改造 `KVStore`，加入 WAL 功能。

```go
package kvstore

import (
	"bufio"
	"encoding/gob"
	"fmt"
	"io"
	"os"
	"sync"
)

// logEntry 代表一条操作日志
type logEntry struct {
	Op    string // "SET" or "DELETE"
	Key   string
	Value []byte
}

type KVStore struct {
	mu   sync.RWMutex
	data map[string][]byte
	wal  *os.File
}

func NewKVStore(walPath string) (*KVStore, error) {
	s := &KVStore{
		data: make(map[string][]byte),
	}

	// 打开或创建WAL文件
	f, err := os.OpenFile(walPath, os.O_CREATE|os.O_RDWR|os.O_APPEND, 0644)
	if err != nil {
		return nil, err
	}
	s.wal = f

	// 启动时加载WAL，恢复数据
	if err := s.loadFromWAL(); err != nil {
		return nil, fmt.Errorf("failed to load WAL: %w", err)
	}

	return s, nil
}

// Set 方法改造
func (s *KVStore) Set(key string, value []byte) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	// 1. 先写WAL
	entry := logEntry{Op: "SET", Key: key, Value: value}
	encoder := gob.NewEncoder(s.wal)
	if err := encoder.Encode(entry); err != nil {
		return err // 写日志失败，操作失败
	}

	// 2. 再写内存
	s.data[key] = value
	return nil
}

// Delete 方法改造
func (s *KVStore) Delete(key string) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	// 1. 先写WAL
	entry := logEntry{Op: "DELETE", Key: key}
	encoder := gob.NewEncoder(s.wal)
	if err := encoder.Encode(entry); err != nil {
		return err
	}

	// 2. 再删内存
	delete(s.data, key)
	return nil
}

// loadFromWAL 从日志文件中恢复数据
func (s *KVStore) loadFromWAL() error {
    // 将文件指针移到开头
	s.wal.Seek(0, 0)
	
	decoder := gob.NewDecoder(s.wal)
	for {
		var entry logEntry
		if err := decoder.Decode(&entry); err != nil {
			if err == io.EOF {
				break // 文件读完了
			}
			return err
		}
		
		// 在内存中重放操作
		switch entry.Op {
		case "SET":
			s.data[entry.Key] = entry.Value
		case "DELETE":
			delete(s.data, entry.Key)
		}
	}
	// 恢复后，文件指针需要回到末尾以继续追加
	s.wal.Seek(0, io.SeekEnd) 
	return nil
}

// Close 关闭文件句柄
func (s *KVStore) Close() error {
	return s.wal.Close()
}
```

**关键细节**：
*   **日志格式**：这里我们使用了 Go 的 `encoding/gob` 包，它可以方便地序列化 Go 的结构体。在生产环境中，可能会选择 Protobuf 或其他更高效、支持跨语言的格式。
*   **WAL 的问题**：日志文件会无限增长。成熟的 KV 数据库会有日志压缩（Compaction）和快照（Snapshot）机制。例如，当日志文件达到一定大小时，将当前内存中的所有数据完整地写入一个新的快照文件，并清空旧的日志。这样下次启动时，只需加载快照，再回放快照之后的新日志即可，大大加快了恢复速度。

### 第四步：管理时效性 - 增加 TTL 过期机制

在很多场景下，我们存入的数据并不需要永久有效。比如“学术推广平台”中的用户登录 Token，或者“智能监测系统”的短期告警抑制状态。这些数据过期后需要被自动删除，这就是 TTL (Time-To-Live)。

实现 TTL 的思路是在存储的值中附加一个过期时间戳。

**1. 改造存储结构**

```go
// valueEntry 包装了真实值和过期时间
type valueEntry struct {
	Value    []byte
	ExpireAt int64 // Unix时间戳 (秒)，0表示永不过期
}

// KVStore 的 data 字段需要修改
type KVStore struct {
	// ...
	data map[string]valueEntry
    // ...
}
```

**2. 改造 `Set` 和 `Get` 方法**

`Set` 方法需要接收一个额外的 `ttl` 参数（单位秒）。

```go
// Set 方法新签名
func (s *KVStore) Set(key string, value []byte, ttl int64) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	var expireAt int64
	if ttl > 0 {
		expireAt = time.Now().Unix() + ttl
	}

    // valueEntry 也需要写入WAL，所以logEntry也需要调整
	entry := valueEntry{Value: value, ExpireAt: expireAt}
    // ... 将包含valueEntry的log写入WAL ...
	s.data[key] = entry
	return nil
}
```

`Get` 方法在返回数据前，需要检查是否过期。

```go
func (s *KVStore) Get(key string) ([]byte, bool) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	entry, found := s.data[key]
	if !found {
		return nil, false
	}

	// 检查是否过期
	if entry.ExpireAt > 0 && time.Now().Unix() > entry.ExpireAt {
		// 这里有个优化点：发现过期数据时，可以惰性删除
		// 但惰性删除需要获取写锁，会使Get变慢，需要权衡
		// 我们先只返回不存在
		return nil, false
	}

	return entry.Value, true
}
```

**3. 实现后台清理 Goroutine**

仅仅在 `Get` 时检查是不够的，如果一个过期的键再也不被访问，它将永远占用内存。我们需要一个后台任务定期扫描并清理过期的键。

```go
func (s *KVStore) StartGC(interval time.Duration) {
	ticker := time.NewTicker(interval)
	go func() {
		for range ticker.C {
			s.cleanupExpiredKeys()
		}
	}()
}

func (s *KVStore) cleanupExpiredKeys() {
	// 为了避免长时间锁住整个map，可以随机采样一部分key进行检查
	// 或者复制一份key列表再慢慢处理
	var keysToDelete []string
	
	s.mu.RLock() // 先用读锁遍历
	for k, v := range s.data {
		if v.ExpireAt > 0 && time.Now().Unix() > v.ExpireAt {
			keysToDelete = append(keysToDelete, k)
		}
	}
	s.mu.RUnlock()
	
	if len(keysToDelete) > 0 {
		s.mu.Lock() // 获取写锁，批量删除
		for _, k := range keysToDelete {
			// 再次确认，防止在读锁释放到写锁获取期间，该key被更新
			if v, ok := s.data[k]; ok && v.ExpireAt > 0 && time.Now().Unix() > v.ExpireAt {
				// 注意：删除操作也应该写入WAL
                // ... 写入DELETE操作到WAL ...
				delete(s.data, k)
			}
		}
		s.mu.Unlock()
	}
}
```

**关键细节**：
*   **清理策略**：全量扫描 `map` 在数据量大时会造成性能抖动。Redis 采用的是定期抽样扫描+惰性删除结合的策略，是很好的借鉴。
*   **分布式锁**：如果你的 KV 服务是集群部署的，清理任务需要在节点间同步，避免重复工作，这通常需要借助分布式锁（如基于 Etcd 或 Zookeeper 实现）。

### 总结与展望

到这里，我们已经一步步构建了一个具备核心功能（线程安全、API服务、持久化、TTL）的嵌入式 KV 数据库。虽然距离 BoltDB 或 Badger 这样的工业级项目还有很大差距（例如缺少事务、高效索引、MVCC等），但它已经能在我们的一些特定业务场景中发挥巨大作用。

我一直认为，学习技术的最好方式，就是把它应用到真实的业务问题中去。从一个简单的 `map` 出发，为了解决并发问题加上锁，为了解决数据丢失问题加上 WAL，为了解决内存占用问题加上 TTL…… 每一步优化，都是由实际需求驱动的。

希望我的这点经验，能帮助正在学习 Go 的你，更好地理解理论与实践之间的联系。如果你对我们临床医疗行业的后端技术感兴趣，或者在 Go 开发中遇到任何问题，欢迎随时交流。