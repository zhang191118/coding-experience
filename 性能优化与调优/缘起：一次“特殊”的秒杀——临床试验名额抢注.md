### 缘起：一次“特殊”的秒杀——临床试验名额抢注

大家可能觉得，我们做医疗软件的，跟“秒杀”这种电商场景八竿子打不着。但实际上，我们遇到了一个极其相似的场景。

去年，我们为一个备受关注的肿瘤新药 I 期临床试验开发线上受试者招募系统。这个项目非常特殊，全国范围内只开放 50 个名额，但潜在的报名患者可能有数万人。招募通道一开放，系统必然会面临远超平时百倍、甚至千倍的瞬时请求压力。

这本质上就是一个“秒杀”：**商品是极其有限的试验名额，用户是焦急等待的患者**。我们的挑战是：

1.  **绝对不能超额招募**：多一个都不行，这在临床试验中是极其严重的合规问题。
2.  **系统不能崩溃**：要保证在高流量下服务的可用性，给所有患者一个公平的机会。
3.  **响应要快**：患者点击报名后，必须在短时间内得到明确的结果——成功或者名额已满。

面对这个挑战，我们技术选型的第一反应就是 Go + Redis。Go 的 `goroutine` 并发模型天生适合应对这类 I/O 密集型的高并发场景，而 Redis 基于内存的高速读写和原子操作能力，是处理“名额”这种高竞争性资源的不二之选。

---

### 第一章：地基搭建——Go 并发模型的深入理解

要用好 Go，就必须理解它的并发为什么快。很多初学者知道 `go` 关键字能开一个 goroutine，但对其背后的 GMP 调度模型了解不深，这在高并发编程中是远远不够的。

#### 1.1 万丈高楼平地起：GMP 调度模型

简单来说，操作系统调度线程（M）的开销很大，而 Go 在用户态自己实现了一套更轻量、更高效的调度逻辑（P），用来调度自己的“线程”——Goroutine（G）。

*   **G (Goroutine)**：你可以理解为一个轻量级的执行任务，创建一个 Goroutine 只需 2KB 左右的栈内存。
*   **M (Machine)**：代表一个真正的操作系统线程。
*   **P (Processor)**：一个逻辑处理器，是 G 和 M 之间的“调度官”。它有一个本地的 Goroutine 队列，M 需要绑定一个 P 才能执行 P 队列里的 G。


![GMP模型](https://raw.githubusercontent.com/ray-guo/images/master/20240921151614.png)


这种模型的好处是，Goroutine 的调度切换发生在用户态，成本极低。当一个 Goroutine 因为网络 I/O 等待时，P 会立刻将 M 和另一个可运行的 Goroutine 绑定，而不是让整个线程傻等。这就是 Go 能用少量线程支撑大量并发请求的核心秘密。

#### 1.2 实战：用 Goroutine 处理海量报名请求

在我们的招募系统中，每一个报名请求都由一个独立的 Goroutine 来处理。我们使用 `go-zero` 框架，这在代码层面是无感的，框架底层已经帮我们处理好了。

我们来看一下 `go-zero` 中一个简化版的报名接口 handler：

```go
// file: recruit/internal/logic/enrolllogic.go

package logic

import (
	"context"
	// ...
)

type EnrollLogic struct {
	logx.Logger
	ctx    context.Context
	svcCtx *svc.ServiceContext
}

// NewEnrollLogic ...
func NewEnrollLogic(ctx context.Context, svcCtx *svc.ServiceContext) *EnrollLogic {
	return &EnrollLogic{
		Logger: logx.WithContext(ctx),
		ctx:    ctx,
		svcCtx: svcCtx,
	}
}

// Enroll 处理患者报名请求
func (l *EnrollLogic) Enroll(req *types.EnrollReq) (resp *types.EnrollResp, err error) {
	// 1. 从 context 获取 userId (通常由 JWT 中间件注入)
	userId, ok := l.ctx.Value("userId").(int64)
	if !ok {
		return nil, errors.New("获取用户信息失败")
	}

	// 2. 调用 Redis 核心逻辑，尝试抢占名额
	// 这里是关键，我们把所有复杂性都封装到 Redis 脚本里
	success, err := l.svcCtx.RedisClient.AttemptEnroll(l.ctx, req.TrialID, userId)
	if err != nil {
		// 记录严重错误，可能是 Redis 挂了
		l.Logger.Errorf("Redis 报名处理异常: %v", err)
		return nil, errors.New("系统繁忙，请稍后再试")
	}

	if !success {
		return &types.EnrollResp{
			Success: false,
			Message: "抱歉，名额已满或您已报名",
		}, nil
	}

	// 3. 名额抢占成功，发送一个异步消息，让其他服务去处理后续流程
	// 例如：生成报名记录、发送通知短信等
	// 注意：这里不能做任何耗时操作，要立刻返回
	if err := l.svcCtx.KqPusher.Push(fmt.Sprintf("enroll_success:%d:%d", req.TrialID, userId)); err != nil {
        // 消息发送失败需要有补偿机制，这里先只记录日志
        l.Logger.Errorf("发送报名成功消息失败: %v", err)
    }

	return &types.EnrollResp{
		Success: true,
		Message: "恭喜您，报名成功！",
	}, nil
}
```

每个请求进来，`go-zero` 都会从协程池里取一个 Goroutine 来执行 `Enroll` 方法。我们在这个方法里只做了两件核心的事：**调用 Redis 判断和抢占名额**、**发送异步消息**。整个过程非常快，没有任何阻塞性的数据库操作。

#### 1.3 别把锁用错了地方：`sync.Mutex` 的局限性

在项目初期，有同事提出：“我们能不能在服务内存里用一个 `map` 记录已报名的用户，再用一个 `sync.Mutex` 保护这个 `map` 和剩余名额计数器？”

这是个很好的问题，也暴露了一个常见的误区。`sync.Mutex` 是 Go 提供的非常高效的**单进程内**锁。但在我们的生产环境中，招募服务至少会部署两个以上的 Pod（实例）来保证高可用。

如果你在一个 Pod A 的内存里加了锁，它完全管不到另一个 Pod B。两个 Pod 同时处理请求，各自都认为自己拿到了锁，最后名额还是会被超额分配。这就是为什么在高并发分布式系统中，我们必须依赖像 Redis 这样的外部组件来实现**分布式锁**或**原子计数**。

---

### 第二章：核心武器——Redis 原子操作与 Lua 脚本

我们的方案成功的关键，就是把最核心、竞争最激烈的“名额库存”，完全交给了 Redis 来管理。

#### 2.1 原子性：Redis 如何保证“一个不多，一个不少”

Redis 的命令执行是单线程的。这意味着当你发送一个命令（比如 `DECR`）时，在它执行完成之前，其他任何客户端的命令都不能插队。这个特性就是我们保证数据一致性的基石。

**第一步：初始化名额**

服务启动前，我们会手动或通过脚本在 Redis 中初始化试验名額：

```sh
# trial:slots:oncology_a001 是我们设计的 key，oncology_a001 是试验的唯一标识
# 值为 50，代表有 50 个名额
SET trial:slots:oncology_a001 50

# 同时创建一个 set，用来存放成功报名的用户ID，防止重复报名
# SADD trial:users:oncology_a001 0
# (可以先不创建，在第一个用户报名时会自动创建)
```

**第二步：天真的扣减方案（错误示范）**

最简单的想法是：

1.  用 `GET` 命令查一下名额还够不够。
2.  如果够，用 `DECR` 命令减一个名额。
3.  用 `SADD` 把用户 ID 加到集合里。

在高并发下，这个流程是**完全错误**的。假设现在只剩 1 个名额，两个请求（用户 A 和 B）同时执行到第一步，它们都查到名额是 1，都认为自己可以报名。结果，名额被减成了 -1，两个用户都报名成功了。这就是典型的“超卖”问题。

#### 2.2 终极方案：Lua 脚本实现“查重、检查、扣减”三合一原子操作

为了解决上述问题，我们需要把“检查用户是否已报名”、“检查名额是否大于 0”、“扣减名额”、“记录用户 ID”这几个步骤合并成一个**原子操作**。

这就是 Lua 脚本的用武之地。Redis 保证整个 Lua 脚本的执行是原子的。

```lua
-- attempt_enroll.lua

-- KEYS[1]: 名额计数的 key，例如 "trial:slots:oncology_a001"
-- KEYS[2]: 已报名用户集合的 key，例如 "trial:users:oncology_a001"
-- ARGV[1]: 当前尝试报名的用户 ID

-- 1. 检查用户是否已经报名
if redis.call('SISMEMBER', KEYS[2], ARGV[1]) == 1 then
  return 0 -- 0 代表重复报名
end

-- 2. 获取当前剩余名额
local stock = tonumber(redis.call('GET', KEYS[1]))
if not stock or stock <= 0 then
  return 1 -- 1 代表名额已空
end

-- 3. 执行扣减和记录操作
redis.call('DECR', KEYS[1])
redis.call('SADD', KEYS[2], ARGV[1])

return 2 -- 2 代表报名成功
```

在 Go 代码中，我们加载并执行这个脚本：

```go
// file: recruit/internal/svc/servicecontext.go (部分代码)
// RedisClient 封装了对 Redis 的操作

// AttemptEnroll 尝试为用户报名临床试验
func (r *RedisClient) AttemptEnroll(ctx context.Context, trialID string, userID int64) (bool, error) {
    // Lua 脚本，实际项目中会从文件加载或预加载到 Redis
    script := `
        if redis.call('SISMEMBER', KEYS[2], ARGV[1]) == 1 then
          return 0
        end
        local stock = tonumber(redis.call('GET', KEYS[1]))
        if not stock or stock <= 0 then
          return 1
        end
        redis.call('DECR', KEYS[1])
        redis.call('SADD', KEYS[2], ARGV[1])
        return 2`

    keys := []string{
        fmt.Sprintf("trial:slots:%s", trialID),
        fmt.Sprintf("trial:users:%s", trialID),
    }
    args := []interface{}{userID}

    // 执行脚本
    res, err := r.Eval(ctx, script, keys, args...).Result()
    if err != nil {
        return false, err
    }

    // 根据返回值判断结果
    if code, ok := res.(int64); ok && code == 2 {
        return true, nil // 只有返回 2 才算成功
    }

    return false, nil // 其他情况都算失败
}
```

通过这个 Lua 脚本，我们把所有关键逻辑都放在了 Redis 服务端，用一条命令就完成了原先需要多次网络交互和可能产生并发问题的操作。这既保证了原子性，又极大地提升了性能。

---

### 第三章：细节是魔鬼——那些决定成败的关键点

架构方案定了，但真正落地时，还有很多细节会影响系统的稳定性和性能。

#### 3.1 接口限流：保护你的系统不被“打死”

即使后端能处理，我们也不希望所有流量都毫无阻拦地打到核心服务上。万一有恶意攻击或者爬虫怎么办？

限流是第一道防线。我们在 `go-zero` 的 API 网关层和业务服务层都配置了限流。`go-zero` 自带了基于令牌桶算法的限流中间件，配置非常简单。

在 `enroll.api` 文件中定义路由时加上中间件：

```api
// file: recruit/api/enroll.api

@server(
    jwt: Auth
    middleware: RateLimit // 引用限流中间件
)
service enroll-api {
    @handler Enroll
    post /enroll (EnrollReq) returns (EnrollResp)
}
```

然后在服务的 `config.yaml` 中配置限流参数：

```yaml
# file: recruit/etc/config.yaml

RateLimit:
  Period: 1 # 窗口时间，单位：秒
  Quota: 100 # 每个窗口允许通过的请求数
  Redis:
    Addr: "redis_host:6379"
    Key: "ratelimit:"
```

这样配置后，对于同一个来源（`go-zero` 默认基于 IP），1 秒内超过 100 次的请求就会被直接拒绝，返回 `429 Too Many Requests`，根本不会到达我们的业务逻辑，极大地减轻了后端的压力。

#### 3.2 异步下单：让用户“秒”速得到反馈

就像前面代码里展示的，当 Lua 脚本返回成功后，我们的 `Enroll` 接口**绝对不能**去做连接数据库、写报名记录、发短信这些耗时操作。

正确的做法是：**同步预占名额，异步处理后续**。

我们将报名成功的消息（包含了试验 ID 和用户 ID）推送到 Kafka 消息队列。然后有一个专门的消费服务（`enroll-consumer`）去订阅这个 Topic，慢悠悠地处理数据库写入、调用 CTMS 接口同步数据等操作。


![异步流程](https://raw.githubusercontent.com/ray-guo/images/master/20240921151639.png)


这样做的好处是：
*   报名接口的响应时间可以控制在 10 毫秒以内，用户体验极佳。
*   核心的招募服务与下游的业务系统完全解耦，即使下游服务（比如短信网关）出现故障，也不会影响到报名主流程。

#### 3.3 热点 Key 问题：防患于未然

虽然我们的系统只处理一个试验项目，但可以预见，如果平台同时为多个项目招募，那么最热门的那个项目的 Redis Key（比如 `trial:slots:oncology_a001`）就会成为一个**热点 Key**。

所有的流量都集中读写这一个 Key，可能会把 Redis 单个 CPU 核心打满，造成性能瓶颈。

对此，我们的应对策略是：

1.  **监控**：我们使用 `redis-cli --hotkeys` 和内部的监控平台，持续监控 Redis 的热点 Key。
2.  **集群化**：我们的 Redis 实例是集群模式（Redis Cluster）。虽然单个 Key 还是会落在一个 slot 上，但集群化提供了更好的整体扩展性和可用性。
3.  **预案**：如果热点问题真的极其严重，我们会考虑更复杂的方案，比如在业务代码层面将一个大库存拆分成多个小库存（`trial:slots:oncology_a001_part1`, `..._part2`），然后随机写入其中一个。但这会大大增加业务逻辑的复杂度，属于万不得已的最后手段。在这次项目中，单个 Key 的方案足以应对。

---

### 总结

最终，我们的这套系统非常平稳地支撑了上线当天前 5 分钟所有名额被抢完的流量高峰，QPS 峰值达到了我们日常业务的 800 多倍，全程没有一个超额报名，也没有一次宕机。

这次经历让我们团队深刻体会到，构建一个高并发系统，技术选型（Go + Redis）只是第一步。更重要的是：

*   **深入理解业务场景**：将“临床试验招募”抽象成“秒杀模型”，是解决问题的关键。
*   **把复杂留给自己，把简单交给用户**：通过 Lua 脚本和异步化，我们把复杂的并发控制和耗时操作都封装在后端，让前端接口极其简单快速。
*   **细节决定成败**：限流、监控、降级预案这些看似“不重要”的环节，才是保证系统在极端情况下依然稳如泰山的“安全绳”。

希望今天的分享，能对大家在未来的工作中处理类似的高并发、高竞争场景有所启发。谢谢大家。